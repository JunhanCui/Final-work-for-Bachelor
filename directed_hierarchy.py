"""
Module: Directed Hierarchy Analysis (DHA) Implementation
Author: [Junhan Cui]
Date: [2023-06-07]
Description: 
    This module implements the DHA (Directed Hierarchy Analysis) algorithm 
    for Topological Data Analysis (TDA).
"""

# Standard library imports
import math

# Third-party imports
import numpy as np
import pandas as pd
from ripser import ripser
from persim import wasserstein as was
from persim import bottleneck as btn

# ---------------------------------------------------------
# Algorithm Implementation
# ---------------------------------------------------------

"""
此处开始，下面这就是我被称为针对性层次分析(Análisis de jerarquía dirigido AJD)的方法
Aquí es donde empiezo; a continuación se presenta lo que llamo el método de análisis jerárquico dirigido (Análisis de jerarquía dirigido AJD).
Starting here, the following is what I call the Directed Hierarchical Analysis (Análisis de jerarquía dirigido, AJD) method.
"""

def ajdcui(data, w, c, diagori, dist):
    
    """
        Computes the Directed Hierarchy Analysis (AJD) distance between persistence diagrams.

        Parameters
        ----------
        data : pd.DataFrame
            The original raw dataset.
            
        w : list of int
            A list of column indices (variables) that have been removed/eliminated 
            in the previous stages of the analysis.
            
        c : int
            The dimension of the homology group to focus on (e.g., 0 for H0, 1 for H1).
            
        diagori : list of np.ndarray
            The reference persistence diagrams. 
            It typically contains diagrams for H0 and H1. Each diagram is an array of shape (N, 2),
            where column 0 represents Birth time and column 1 represents Death time.
            
        dist : str
            The metric used to calculate the topological distance. 
            Supported options:
            - 'was': Wasserstein distance (from optimal transport).
            - 'btn': Bottleneck distance (stability metric).
            - 'pet': Total persistence time (sum of lifespans).
            - 'ent': Persistence entropy (Shannon entropy of the diagram).
            - 'entaproxori': Entropy approximation relative to the original entropy.

        Returns
        -------
        list
            A list containing two elements `[column_index, distance_value]`:
            1. The first component is the column number (index) obtained in this step 
               according to the specified requirements (the optimal variable).
            2. The second component is the calculated distance value corresponding to 
               that specific column.
    """
    
    # Remove variables determined for exclusion in previous steps.
    
    z=np.array(range(data.shape[1]))
    x=data.drop(data.columns[w],axis = 1)
    z=np.delete(z,w)
    distance_dir = np.zeros([len(z),2],float)
    
    # Remove all 0-dimensional homology features (H0) with infinite death times 
    # (i.e., features that persist indefinitely) from the persistence diagram.
        
    if(dist=='ent' and c==0):
        inflist=[]
        for s in range(len(np.isinf(diagori[0][:,1]))):
            if (np.isinf(diagori[0][s,1])==True):
                inflist.append(s)
        
        for s in range(len(inflist)):
            diagori[0]=np.delete(diagori[0],inflist[s],axis=0)

    if(dist=='pet' and c==0):
        inflist=[]
        for s in range(len(np.isinf(diagori[0][:,1]))):
            if (np.isinf(diagori[0][s,1])==True):
                inflist.append(s)
        
        for s in range(len(inflist)):
            diagori[0]=np.delete(diagori[0],inflist[s],axis=0)
    
    #------------------------------------------------------------------------
    # Distance Calculation Strategy
    # -------------------------------------------------------------------------
    # Compute the distance value based on the selected dimension 'c' and metric 'dist':
    # 
    # 1. 'was': Wasserstein distance between the current persistence diagram ('diagrams_i', 
    #           generated by variables/principal components retained in this step) 
    #           and the original persistence diagram ('diagori').
    # 2. 'btn': Bottleneck distance between 'diagrams_i' and 'diagori'.
    # 3. 'pet': Total persistence (sum of all lifetimes) of the current diagram 'diagrams_i'.
    # 4. 'ent': Topological persistence entropy of the original diagram 'diagori'.
    # 5. 'entaproxori': Means 'The entropy that approximate the original one'.
    #                   The difference of topological persistence entropy in
    #                   'diagrams_i' and 'diagori'.
    # -------------------------------------------------------------------------
    
    for i in range(len(z)):

        datos_i = x.drop(x.columns[i],axis = 1)
        diagrams_i = ripser(datos_i)['dgms']

        if(dist=='was'):
            if(c==0):
                distance = was(diagrams_i[0], diagori[0])
            elif(c==1):
                distance = was(diagrams_i[1], diagori[1])
        
        elif(dist=='btn'):
            if(c==0):
                distance = btn(diagrams_i[0], diagori[0])
            elif(c==1):
                distance = btn(diagrams_i[1], diagori[1])
        
        elif(dist=='pet'):
            if(c==0):
                inflist=[]
                for s in range(len(np.isinf(diagrams_i[0][:,1]))):
                    if (np.isinf(diagrams_i[0][s,1])==True):
                        inflist.append(s)
                
                for s in range(len(inflist)):
                    diagrams_i[0]=np.delete(diagrams_i[0],inflist[s],axis=0)
                
                distance = (diagrams_i[0][:,1]-diagrams_i[0][:,0]).sum()

            if(c==1):
                distance = (diagrams_i[1][:,1]-diagrams_i[1][:,0]).sum()
        
        elif(dist=='ent'):
            if(c==0):
                inflist=[]
                for s in range(len(np.isinf(diagrams_i[0][:,1]))):
                    if (np.isinf(diagrams_i[0][s,1])==True):
                        inflist.append(s)

                for s in range(len(inflist)):
                    diagrams_i[0]=np.delete(diagrams_i[0],inflist[s],axis=0)

                per_total = (diagrams_i[0][:,1]-diagrams_i[0][:,0]).sum()
                entropia = 0
                for j in range(diagrams_i[0].shape[0]):
                    entropia=entropia-((diagrams_i[0][j,1]-diagrams_i[0][j,0])/per_total)*np.log2((diagrams_i[0][j,1]-diagrams_i[0][j,0])/per_total)
                
                distance = entropia
            
            if(c==1):
                per_total = (diagrams_i[1][:,1]-diagrams_i[1][:,0]).sum()
                entropia = 0
                for j in range(diagrams_i[1].shape[0]):
                    entropia=entropia-((diagrams_i[1][j,1]-diagrams_i[1][j,0])/per_total)*np.log2((diagrams_i[1][j,1]-diagrams_i[1][j,0])/per_total)
                
                distance = entropia

        elif(dist=='entaproxori'):
            if(c==0):
                inflist=[]
                for s in range(len(np.isinf(diagrams_i[0][:,1]))):
                    if (np.isinf(diagrams_i[0][s,1])==True):
                        inflist.append(s)
                
                for s in range(len(inflist)):
                    diagrams_i[0]=np.delete(diagrams_i[0],inflist[s],axis=0)

                per_total = (diagrams_i[0][:,1]-diagrams_i[0][:,0]).sum()
                entropia = 0
                for j in range(diagrams_i[0].shape[0]):
                    entropia=entropia-((diagrams_i[0][j,1]-diagrams_i[0][j,0])/per_total)*np.log2((diagrams_i[0][j,1]-diagrams_i[0][j,0])/per_total)
                
                entori=0
                per_ori = (diagori[0][:,1]-diagori[0][:,0]).sum()
                for j in range(diagori[0].shape[0]):
                    entori=entori-((diagori[0][j,1]-diagori[0][j,0])/per_ori)*np.log2((diagori[0][j,1]-diagori[0][j,0])/per_ori)
                
                difference=abs(entropia-entori)

                distance = difference

            if(c==1):
                per_total = (diagrams_i[1][:,1]-diagrams_i[1][:,0]).sum()
                entropia = 0
                for j in range(diagrams_i[1].shape[0]):
                    entropia=entropia-((diagrams_i[1][j,1]-diagrams_i[1][j,0])/per_total)*np.log2((diagrams_i[1][j,1]-diagrams_i[1][j,0])/per_total)
                
                entori=0
                per_ori = (diagori[1][:,1]-diagori[1][:,0]).sum()
                for j in range(diagori[1].shape[0]):
                    entori=entori-((diagori[1][j,1]-diagori[1][j,0])/per_ori)*np.log2((diagori[1][j,1]-diagori[1][j,0])/per_ori)
                
                difference=abs(entropia-entori)

                distance = difference

        colname=int(x.columns.values[i])
        distance_dir[i]=(distance,colname)

    # -------------------------------------------------------------------------
    # Metric Selection Strategy (Minimization vs. Maximization)
    # -------------------------------------------------------------------------
    # Determine the optimal variable (column) to remove/keep based on the metric:
    #
    # 1. For 'was' (Wasserstein) and 'btn' (Bottleneck):
    #    Strategy: Select the MINIMUM distance.
    #    Reasoning: These distances measure the deviation between the current diagram 
    #    and the original diagram. Minimizing this distance ensures that the 
    #    reduced dataset (after PCA/variable selection) preserves the original 
    #    topological structure as much as possible (least structural distortion).
    #
    # 2. For 'pet' (Total Persistence) and 'ent' (Persistence Entropy):
    #    Strategy: Select the MAXIMUM value.
    #    Reasoning: These metrics quantify the amount of topological information 
    #    or signal strength. Maximizing them ensures that we retain the most 
    #    significant topological features and avoid losing critical structural information.
    #
    # 3. For 'entaproxori' (Entropy Approximation):
    #    Strategy: Select the MINIMUM difference.
    #    Reasoning: This minimizes the divergence between the current entropy and 
    #    the original entropy. A smaller difference implies that the reduced dataset 
    #    maintains a level of topological complexity closest to the original dataset.
    # -------------------------------------------------------------------------
    
    if(dist=='btn' or dist=='was'):
        list_distance_dir=distance_dir[:,0].tolist()
        min_dist = list_distance_dir.index(min(distance_dir[:,0]))
        col_min_dist = distance_dir[min_dist,1]

        return [int(col_min_dist),min(distance_dir[:,0])]

    if(dist=='pet'):
        list_distance_dir=distance_dir[:,0].tolist()
        max_dist = list_distance_dir.index(max(distance_dir[:,0]))
        col_max_dist = distance_dir[max_dist,1]

        return [int(col_max_dist),max(distance_dir[:,0])]
    
    if(dist=='ent'):
        list_distance_dir=distance_dir[:,0].tolist()
        max_dist = list_distance_dir.index(max(distance_dir[:,0]))
        col_max_dist = distance_dir[max_dist,1]

        return [int(col_max_dist),max(distance_dir[:,0])]

    if(dist=='entaproxori'):
        list_distance_dir=distance_dir[:,0].tolist()
        min_dist = list_distance_dir.index(min(distance_dir[:,0]))
        col_min_dist = distance_dir[min_dist,1]

        return [int(col_min_dist),min(distance_dir[:,0])]